{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Data Structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An HDF5 data container is a standardized, highly-customizable data receptacle designed for portability.\n",
    "\n",
    "Our physics data samples will be provided in h5 format. Get access to it [here](https://drive.google.com/drive/u/3/folders/1j5iMgARqRhtrMmVHDfM9o2XRTXXlZgcI).\n",
    "\n",
    "## Accessing the Data: Part 1\n",
    "\n",
    "Navigate to the directory where you've saved the processed-pythia.z data file. Mine is saved in 'Deep-Learning-Model-Evaluation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\alexc\\\\OneDrive\\\\Projects\\\\Deep-Learning-Model-Evaluation\\\\1 layer NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_truth.z', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['t_allpar_new']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('j_ptfrac', 'j_pt', 'j_eta', 'j_mass', 'j_tau1_b1', 'j_tau2_b1', 'j_tau3_b1', 'j_tau1_b2', 'j_tau2_b2', 'j_tau3_b2', 'j_tau32_b1', 'j_tau32_b2', 'j_zlogz', 'j_c1_b0', 'j_c1_b1', 'j_c1_b2', 'j_c2_b1', 'j_c2_b2', 'j_d2_b1', 'j_d2_b2', 'j_d2_a1_b1', 'j_d2_a1_b2', 'j_m2_b1', 'j_m2_b2', 'j_n2_b1', 'j_n2_b2', 'j_tau1_b1_mmdt', 'j_tau2_b1_mmdt', 'j_tau3_b1_mmdt', 'j_tau1_b2_mmdt', 'j_tau2_b2_mmdt', 'j_tau3_b2_mmdt', 'j_tau32_b1_mmdt', 'j_tau32_b2_mmdt', 'j_c1_b0_mmdt', 'j_c1_b1_mmdt', 'j_c1_b2_mmdt', 'j_c2_b1_mmdt', 'j_c2_b2_mmdt', 'j_d2_b1_mmdt', 'j_d2_b2_mmdt', 'j_d2_a1_b1_mmdt', 'j_d2_a1_b2_mmdt', 'j_m2_b1_mmdt', 'j_m2_b2_mmdt', 'j_n2_b1_mmdt', 'j_n2_b2_mmdt', 'j_mass_trim', 'j_mass_mmdt', 'j_mass_prun', 'j_mass_sdb2', 'j_mass_sdm1', 'j_multiplicity', 'j_g', 'j_q', 'j_w', 'j_z', 'j_t', 'j_undef')\n"
     ]
    }
   ],
   "source": [
    "treeArray = f['t_allpar_new'][()] #Empty tuple indexing retrieves all values\n",
    "print(treeArray.dtype.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data\n",
    "The structure of a jet is introduced in tutorial 12 from the computing tutorial. It is very important to understand the structure of the sample in order to see the applications of different network types. \n",
    "\n",
    "In our pre-processed sample, each row is a jet with the above features. The two and four layer networks use the features of the jet to classify whether the jet originated from the decay a top quark or not.\n",
    "\n",
    "The features/inputs we will use are\n",
    "\n",
    "\n",
    "\n",
    "|    Features    |    Labels     |\n",
    "|  :-------:     |  :---------:  |\n",
    "|  j_zlogz       |  j_t          |\n",
    "|  j_c1_b0_mmdt        |               |\n",
    "|  j_c1_b1_mmdt        |               |\n",
    "|  j_c2_b1_mmdt        |               |\n",
    "|  j_d2_b1_mmdt        |               |\n",
    "|  j_d2_a1_b1_mmdt        |               |\n",
    "|  j_m2_b1_mmdt        |               |\n",
    "|  j_n2_b1_mmdt        |               |\n",
    "|  j_mass_mmdt        |               |\n",
    "|  j_multiplicity       |               |\n",
    "\n",
    "And clearly our label will be top quark or not. A training sample contains both features and labels.\n",
    "\n",
    "Not all networks use the already-clustered jets' features to classify the elementary particles from which they originated. The best performing ones are usually either _constituent_ or _image_ based classifiers. \n",
    "\n",
    "[ResNet-50](https://arxiv.org/pdf/1512.03385.pdf) is an example of an image-based classifier which achieves state of the art performance, with an input layer populated by the pixels in a _jet image_. The sensors on the inside surface of the cylindrical detectors can be represented in a two dimensional histogram of $\\eta$ and $\\phi$, and activation of these pixels is the energy or transverse momentum transferred to the sensors. This decision influences the architecture of the network as well as its performance; it requires immense amounts of data and computational power to train, as training time is proportional to the number of neurons a network needs to train (and with a 244x244 pixel image, thats an input layer of nearly 60,000 neurons). \n",
    "\n",
    "[Long Short-Term Memory](https://arxiv.org/pdf/1711.09059.pdf) (More [here](https://www.sciencedirect.com/science/article/pii/S0167278919305974)) is an example of a network which excells at consituent-based classification. The jets in our data sample come pre-clustered and pre-processed; with constituent based classifiers, the particles composing the jet itself are each individually analyzed. Constituent-based classification makes sense for a recurring neural network like LSTM, as the last constituent ought to influence the classification of the next constituent of the same jet. With a relatively small list of inputs and a simple network architecture, the LSTM network achieves very good performance with O(1000) neurons making it very quick to train and requires comparitively fewer data points to train.\n",
    "\n",
    "## Accessing the Data: Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['j_zlogz', 'j_c1_b0_mmdt', 'j_c1_b1_mmdt', 'j_c2_b1_mmdt', 'j_d2_b1_mmdt', 'j_d2_a1_b1_mmdt',\n",
    "            'j_m2_b1_mmdt', 'j_n2_b1_mmdt', 'j_mass_mmdt', 'j_multiplicity']\n",
    "labels = ['j_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['j_zlogz',\n",
       " 'j_c1_b0_mmdt',\n",
       " 'j_c1_b1_mmdt',\n",
       " 'j_c2_b1_mmdt',\n",
       " 'j_d2_b1_mmdt',\n",
       " 'j_d2_a1_b1_mmdt',\n",
       " 'j_m2_b1_mmdt',\n",
       " 'j_n2_b1_mmdt',\n",
       " 'j_mass_mmdt',\n",
       " 'j_multiplicity',\n",
       " 'j_t']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features+labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_labels_df = pd.DataFrame(treeArray,columns=features+labels)\n",
    "features_labels_df = features_labels_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j_zlogz</th>\n",
       "      <th>j_c1_b0_mmdt</th>\n",
       "      <th>j_c1_b1_mmdt</th>\n",
       "      <th>j_c2_b1_mmdt</th>\n",
       "      <th>j_d2_b1_mmdt</th>\n",
       "      <th>j_d2_a1_b1_mmdt</th>\n",
       "      <th>j_m2_b1_mmdt</th>\n",
       "      <th>j_n2_b1_mmdt</th>\n",
       "      <th>j_mass_mmdt</th>\n",
       "      <th>j_multiplicity</th>\n",
       "      <th>j_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.901162</td>\n",
       "      <td>0.462566</td>\n",
       "      <td>0.039364</td>\n",
       "      <td>0.035541</td>\n",
       "      <td>0.902895</td>\n",
       "      <td>0.902895</td>\n",
       "      <td>0.069127</td>\n",
       "      <td>0.215783</td>\n",
       "      <td>79.503227</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.112807</td>\n",
       "      <td>0.460751</td>\n",
       "      <td>0.049826</td>\n",
       "      <td>0.039287</td>\n",
       "      <td>0.788490</td>\n",
       "      <td>0.788490</td>\n",
       "      <td>0.066843</td>\n",
       "      <td>0.200235</td>\n",
       "      <td>81.145767</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.363088</td>\n",
       "      <td>0.474168</td>\n",
       "      <td>0.060443</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>1.555191</td>\n",
       "      <td>1.555191</td>\n",
       "      <td>0.126817</td>\n",
       "      <td>0.380907</td>\n",
       "      <td>97.876595</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.287620</td>\n",
       "      <td>0.383430</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>1.967673</td>\n",
       "      <td>1.967673</td>\n",
       "      <td>0.109983</td>\n",
       "      <td>0.369561</td>\n",
       "      <td>17.177235</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.878532</td>\n",
       "      <td>0.453209</td>\n",
       "      <td>0.047442</td>\n",
       "      <td>0.036979</td>\n",
       "      <td>0.779445</td>\n",
       "      <td>0.779445</td>\n",
       "      <td>0.066729</td>\n",
       "      <td>0.200641</td>\n",
       "      <td>92.293953</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986801</th>\n",
       "      <td>-2.687196</td>\n",
       "      <td>0.443691</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>0.078020</td>\n",
       "      <td>1.221655</td>\n",
       "      <td>1.221655</td>\n",
       "      <td>0.088727</td>\n",
       "      <td>0.257189</td>\n",
       "      <td>123.400360</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986802</th>\n",
       "      <td>-2.218838</td>\n",
       "      <td>0.372641</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>1.438412</td>\n",
       "      <td>1.438412</td>\n",
       "      <td>0.101022</td>\n",
       "      <td>0.316370</td>\n",
       "      <td>5.798234</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986803</th>\n",
       "      <td>-2.652741</td>\n",
       "      <td>0.446208</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.025503</td>\n",
       "      <td>0.635463</td>\n",
       "      <td>0.635463</td>\n",
       "      <td>0.043024</td>\n",
       "      <td>0.146011</td>\n",
       "      <td>79.840851</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986804</th>\n",
       "      <td>-2.544672</td>\n",
       "      <td>0.392504</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>2.203917</td>\n",
       "      <td>2.203917</td>\n",
       "      <td>0.106957</td>\n",
       "      <td>0.386887</td>\n",
       "      <td>23.755823</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986805</th>\n",
       "      <td>-2.320960</td>\n",
       "      <td>0.415938</td>\n",
       "      <td>0.029118</td>\n",
       "      <td>0.085272</td>\n",
       "      <td>2.928458</td>\n",
       "      <td>2.928458</td>\n",
       "      <td>0.056946</td>\n",
       "      <td>0.331790</td>\n",
       "      <td>82.686821</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>986806 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         j_zlogz  j_c1_b0_mmdt  j_c1_b1_mmdt  j_c2_b1_mmdt  j_d2_b1_mmdt  \\\n",
       "0      -2.901162      0.462566      0.039364      0.035541      0.902895   \n",
       "1      -3.112807      0.460751      0.049826      0.039287      0.788490   \n",
       "2      -3.363088      0.474168      0.060443      0.094000      1.555191   \n",
       "3      -2.287620      0.383430      0.008700      0.017118      1.967673   \n",
       "4      -2.878532      0.453209      0.047442      0.036979      0.779445   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "986801 -2.687196      0.443691      0.063865      0.078020      1.221655   \n",
       "986802 -2.218838      0.372641      0.003415      0.004913      1.438412   \n",
       "986803 -2.652741      0.446208      0.040134      0.025503      0.635463   \n",
       "986804 -2.544672      0.392504      0.012692      0.027972      2.203917   \n",
       "986805 -2.320960      0.415938      0.029118      0.085272      2.928458   \n",
       "\n",
       "        j_d2_a1_b1_mmdt  j_m2_b1_mmdt  j_n2_b1_mmdt  j_mass_mmdt  \\\n",
       "0              0.902895      0.069127      0.215783    79.503227   \n",
       "1              0.788490      0.066843      0.200235    81.145767   \n",
       "2              1.555191      0.126817      0.380907    97.876595   \n",
       "3              1.967673      0.109983      0.369561    17.177235   \n",
       "4              0.779445      0.066729      0.200641    92.293953   \n",
       "...                 ...           ...           ...          ...   \n",
       "986801         1.221655      0.088727      0.257189   123.400360   \n",
       "986802         1.438412      0.101022      0.316370     5.798234   \n",
       "986803         0.635463      0.043024      0.146011    79.840851   \n",
       "986804         2.203917      0.106957      0.386887    23.755823   \n",
       "986805         2.928458      0.056946      0.331790    82.686821   \n",
       "\n",
       "        j_multiplicity  j_t  \n",
       "0                 33.0    0  \n",
       "1                 63.0    1  \n",
       "2                 60.0    1  \n",
       "3                 38.0    0  \n",
       "4                 50.0    1  \n",
       "...                ...  ...  \n",
       "986801            55.0    0  \n",
       "986802            28.0    0  \n",
       "986803            36.0    1  \n",
       "986804            58.0    0  \n",
       "986805            34.0    0  \n",
       "\n",
       "[986806 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above dataframe represents ~1 million jets each with the listed features and labelled as top (1) or not (0).\n",
    "\n",
    "One of the most important steps to ensure the robust-ness of your machine learning solution is to retain a portion of data as a testing set. Understand the testing set's importance [here](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7). It is also imperative to shuffle the data before training a neural network to reach the global minimum of loss as opposed to getting stuck at a local minimum. When trying to create reproducible results, it is also useful to specify a seed for the random number generators.\n",
    "\n",
    "scikit-learn can seperate training and testing sets as well as shuffle the data with the useful method train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_val = features_labels_df[features].values #Convert to numpy array\n",
    "labels_val = features_labels_df[labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_val, labels_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have shuffled training and testing data to use with our model. Now, follow the next tutorial to learn how to build a model.\n",
    "\n",
    "##### Exercise\n",
    "\n",
    "The four-layer model is more generally applicable due to its depth; instead of only tagging jets that originate from top quarks, it can tag jets originating from several different fundamental particles. Extract the training and testing data sets from the sample for the four-layer model training. The features and labels you are trying to extract are:\n",
    "\n",
    "\n",
    "| Features | Labels |\n",
    "|  :---:   |  :--:  |\n",
    "j_zlogz  | j_g \n",
    "j_c1_b0_mmdt | j_q \n",
    "j_c1_b1_mmdt | j_w \n",
    "j_c1_b2_mmdt | j_z\n",
    "j_c2_b1_mmdt | j_t\n",
    "j_c2_b2_mmdt \n",
    "j_d2_b1_mmdt \n",
    "j_d2_b2_mmdt \n",
    "j_d2_a1_b1_mmdt \n",
    "j_d2_a1_b2_mmdt \n",
    "j_m2_b1_mmdt \n",
    "j_m2_b2_mmdt \n",
    "j_n2_b1_mmdt \n",
    "j_n2_b2_mmdt \n",
    "j_mass_mmdt \n",
    "j_multiplicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
