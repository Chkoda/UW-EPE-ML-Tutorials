{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Creating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The open source packages tensorflow and keras do most of the heavy lifting when it comes to machine learning computation. No need to worry about calculus and backpropogation, just build the model and use .fit(). Learn more about the types of models and a little bit about the math behind the keras and tensorflow functions from [UW CSE 416 Spring 2019](https://courses.cs.washington.edu/courses/cse416/19sp/lectures.html) or similiar in content but with complete access [Andrew Ng's Machine Learning Coursera](https://www.coursera.org/learn/machine-learning?utm_source=gg&utm_medium=sem&utm_content=07-StanfordML-US&campaignid=685340575&adgroupid=52515609594&device=c&keyword=machine%20learning%20mooc&matchtype=b&network=g&devicemodel=&adpostion=&creativeid=273169971757&hide_mobile_promo&gclid=Cj0KCQjwuJz3BRDTARIsAMg-HxX7mT2U1X1Abs98BkFp_IKCypGKMbWTjIiwx4GY-C-3LrQ5R82TtrkaAqn4EALw_wcB).\n",
    "\n",
    "Now, for building the two-layer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of the two-layer network includes 10 features,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inputs = Input(shape=(10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbitrarily we choose 32 as the number of neurons in our one hidden layer. This is a hyperparameter that is best optimized through experimentation, and largely dependent on the data set / function the neural network is approximating. [Source](https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/).\n",
    "\n",
    "When you know the function you are trying to approximate has certain characteristics, you can choose an activation function which will approximate the function faster leading to faster training process. ReLu is a good general approximator and Sigmoid is good for classifiers. [Source](https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0)\n",
    "\n",
    "Kernel initialization is an important part of building deep neural networks. Proper initialization will help to extract better features and also to converge faster. So, we have to carefully select our filter initializers, but selecting the kernel initializers is also a kind of hyperparameter tuning (We can't tell exactly which kernel initializers to choose). It all depends on the nature of the dataset and the kind of operation you are going to perform on it. [Source](https://blog.goodaudience.com/visualizing-various-filter-initializers-in-keras-ca14c996db22).\n",
    "\n",
    "For our hidden layer we will use ReLu activation, which is often a good place to start. The output layer will have sigmoid activation, which approximates the ideal classifier function. The initializer is the LeCun uniform initializer. It draws samples from a uniform distribution within [-limit, limit] where the limit is sqrt(3 / N) where N is the number of input units in the weight tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(32, activation='relu', kernel_initializer='lecun_uniform', name='fc1_relu')(Inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layer of our two-layer network is a single label, so there is 1 node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'output_sigmoid')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the [Keras](https://keras.io/api/layers/core_layers/dense/) and [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/lecun_uniform) documentation to understand the syntax better. Tensorflow 2 does the building of a computational graph and execution all in the backend; all thats left is the creation of these connected layers and putting them together in a Model object.\n",
    "\n",
    "The model with one input layer, one hidden layer and one output layer is called a 'two-layer' model because the inputs are not considered an 'active' layer. the four-layer model similiarly has three hidden layers and one output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=Inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two-layer model is complete! Below you can see its structure printed and visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "fc1_relu (Dense)             (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "output_sigmoid (Dense)       (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all thats left is to use the model.fit() method to train it, validate the training, and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "\n",
    "Create the four-layer model. Use 64, 32, and 32 nodes for the first, second, and third hidden layers respectively. For all the hidden layers, use the ReLu activation function and LeCun uniform kernel initializer. Print the summary and the visualization. (Hint: What's different about the output layer?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
